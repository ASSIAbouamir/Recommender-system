"""
Utility functions for RecLM-RAG
"""

import json
import pandas as pd
import numpy as np
from typing import List, Dict, Optional, Any, Any
import requests
from io import BytesIO
from PIL import Image
import re
from pathlib import Path


def download_image(url: str, max_size: int = 224) -> Optional[Image.Image]:
    """Download and resize product image"""
    try:
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            img = Image.open(BytesIO(response.content))
            img.thumbnail((max_size, max_size))
            return img
    except Exception as e:
        pass
    return None


def create_product_card_html(
    asin: str,
    title: str,
    score: float,
    explanation: str,
    image_url: Optional[str] = None,
    price: Optional[float] = None,
    sustainability_score: Optional[float] = None,
    sustainability_reason: Optional[str] = None
) -> str:
    """Create HTML card for product display"""
    image_html = ""
    if image_url:
        image_html = f'<img src="{image_url}" style="max-width:150px;max-height:150px;" />'
    else:
        image_html = '<div style="width:150px;height:150px;background:#f0f0f0;display:flex;align-items:center;justify-content:center;">No Image</div>'
    
    price_html = f"${price:.2f}" if price else "N/A"
    
    # Sustainability badge
    sustainability_html = ""
    if sustainability_score is not None:
        # Color based on score
        if sustainability_score >= 8:
            color = "#28a745"  # Green
        elif sustainability_score >= 6:
            color = "#ffc107"  # Yellow
        else:
            color = "#dc3545"  # Red
        
        sustainability_html = f"""
        <div style="margin-top:8px;padding:8px;background:#f8f9fa;border-radius:4px;border-left:3px solid {color};">
            <p style="margin:0;font-size:12px;font-weight:bold;color:{color};">
                üå± Durabilit√©: {sustainability_score}/10
            </p>
            <p style="margin:4px 0 0 0;font-size:11px;color:#666;">
                {sustainability_reason or "√âvaluation en cours"}
            </p>
        </div>
        """
    
    html = f"""
    <div style="border:1px solid #ddd;border-radius:8px;padding:15px;margin:10px;background:white;">
        <div style="display:flex;gap:15px;">
            <div>{image_html}</div>
            <div style="flex:1;">
                <h3 style="margin:0 0 10px 0;font-size:16px;">{title[:80]}</h3>
                <p style="color:#666;font-size:12px;margin:5px 0;">ASIN: {asin}</p>
                <p style="color:#28a745;font-size:14px;font-weight:bold;margin:5px 0;">Score: {score:.3f} | Price: {price_html}</p>
                {sustainability_html}
                <p style="font-size:13px;color:#555;margin-top:10px;">{explanation}</p>
            </div>
        </div>
    </div>
    """
    return html


def format_user_history(history_df: pd.DataFrame) -> str:
    """Format user history for display"""
    if len(history_df) == 0:
        return "No purchase history"
    
    items = []
    for _, row in history_df.iterrows():
        title = row.get('title', 'Unknown Product')
        rating = row.get('rating', 'N/A')
        items.append(f"‚Ä¢ {title} (Rating: {rating}/5)")
    
    return "\n".join(items[:10])  # Show top 10


def extract_sustainability_keywords(text: str) -> List[str]:
    """Extract sustainability-related keywords"""
    keywords = [
        'organic', 'recycled', 'sustainable', 'eco-friendly', 'vegan',
        'biodegradable', 'compostable', 'carbon neutral', 'fair trade',
        'green', 'environmentally friendly', 'renewable', 'ethical'
    ]
    
    found = []
    text_lower = text.lower()
    for keyword in keywords:
        if keyword in text_lower:
            found.append(keyword)
    
    return found


def evaluate_sustainability_score(
    title: str,
    description: str = "",
    brand: str = "",
    features: str = "",
    keywords: Optional[List[str]] = None,
    llm_client: Optional[object] = None
) -> Dict[str, any]:
    """
    Evaluate product sustainability score from 0 to 10
    
    Args:
        title: Product title
        description: Product description
        brand: Brand name
        features: Product features
        keywords: Detected sustainability keywords
        llm_client: Optional LLM client for advanced evaluation
    
    Returns:
        Dict with 'sustainability_score' (float) and 'short_reason' (str)
    """
    # Extract keywords if not provided
    if keywords is None:
        full_text = f"{title} {description} {features} {brand}".lower()
        keywords = extract_sustainability_keywords(full_text)
    
    # Create evaluation prompt
    keywords_text = ", ".join(keywords) if keywords else "Aucun"
    
    evaluation_prompt = f"""Tu es un expert en durabilit√© et √©co-responsabilit√© produit.

√âvalue ce produit de 0 √† 10 en termes de durabilit√© r√©elle (et pas juste greenwashing).

Crit√®res pris en compte :

- Mat√©riaux recycl√©s, biosourc√©s, certifi√©s (GOTS, OEKO-TEX, etc.)

- Empreinte carbone de fabrication et transport

- Durabilit√© et r√©parabilit√©

- Certifications officielles

- Politique de la marque (B-Corp, 1% for the Planet, etc.)

- Avis clients mentionnant la long√©vit√© ou l'√©thique

R√©ponds EXACTEMENT avec ce format (rien d'autre) :

{{"sustainability_score": 8.7, "short_reason": "Cuir de pomme recycl√©, marque B-Corp, fabriqu√© en Italie, r√©parable √† vie"}}

Produit :

Titre : {title}

Description : {description}

Marque : {brand}

Caract√©ristiques : {features}

Mots-cl√©s d√©tect√©s : {keywords_text}
"""
    
    # Try to use LLM if available
    if llm_client and hasattr(llm_client, 'generate'):
        try:
            response = llm_client.generate(evaluation_prompt, temperature=0.2, max_tokens=500)
            # Parse JSON response
            json_match = re.search(r'\{.*?"sustainability_score".*?\}', response, re.DOTALL)
            if json_match:
                eval_data = json.loads(json_match.group(0))
                score = float(eval_data.get('sustainability_score', 0))
                reason = eval_data.get('short_reason', '')
                # Ensure score is between 0 and 10
                score = max(0, min(10, score))
                return {
                    'sustainability_score': score,
                    'short_reason': reason
                }
        except Exception as e:
            print(f"Error evaluating sustainability with LLM: {e}, falling back to rule-based")
    
    # Fallback to rule-based evaluation
    full_text = f"{title} {description} {features} {brand}".lower()
    score = 5.0  # Base score
    reasons = []
    
    # Material certifications (high weight)
    if any(cert in full_text for cert in ['gots', 'oeko-tex', 'bluesign', 'cradle to cradle']):
        score += 2.0
        reasons.append("certification mat√©riaux")
    
    # Recycled materials
    if any(word in full_text for word in ['recycled', 'recycl√©', 'upcycled', 'r√©cup√©r√©']):
        score += 1.5
        reasons.append("mat√©riaux recycl√©s")
    
    # Bio-based materials
    if any(word in full_text for word in ['bio', 'organic', 'biologique', 'biosourc√©', 'cork', 'li√®ge']):
        score += 1.0
        reasons.append("mat√©riaux biosourc√©s")
    
    # Brand certifications
    if any(cert in full_text for cert in ['b-corp', 'b corp', '1% for the planet', 'fair trade', 'commerce √©quitable']):
        score += 1.5
        reasons.append("marque certifi√©e √©thique")
    
    # Repairability
    if any(word in full_text for word in ['r√©parable', 'repairable', 'r√©paration', 'garantie', 'warranty']):
        score += 0.5
        reasons.append("r√©parable")
    
    # Local/EU production
    if any(word in full_text for word in ['made in france', 'fabriqu√© en france', 'made in europe', 'fabriqu√© en europe', 'local']):
        score += 0.5
        reasons.append("production locale")
    
    # Vegan/animal-free
    if any(word in full_text for word in ['vegan', 'v√©gan', 'cruelty-free', 'sans cruaut√©']):
        score += 0.5
        reasons.append("v√©gan")
    
    # Durability keywords
    if any(word in full_text for word in ['durable', 'durability', 'long-lasting', 'r√©sistant', 'robust']):
        score += 0.5
        reasons.append("durable")
    
    # Negative indicators (greenwashing)
    if any(word in full_text for word in ['green', 'eco', '√©co']) and not any(word in full_text for word in ['certified', 'certifi√©', 'recycled', 'recycl√©']):
        score -= 0.5  # Possible greenwashing
    
    # Ensure score is between 0 and 10
    score = max(0, min(10, score))
    
    # Generate short reason
    if reasons:
        short_reason = ", ".join(reasons[:3])  # Top 3 reasons
    else:
        short_reason = "√âvaluation standard"
    
    return {
        'sustainability_score': round(score, 1),
        'short_reason': short_reason
    }


def calculate_ndcg(recommended_ids: List[str], relevant_ids: List[str], k: int = 10) -> float:
    """Calculate NDCG@k metric"""
    if len(relevant_ids) == 0:
        return 0.0
    
    # Take top k
    recommended_ids = recommended_ids[:k]
    relevant_set = set(relevant_ids)
    
    # Calculate DCG
    dcg = 0.0
    for i, item_id in enumerate(recommended_ids):
        if item_id in relevant_set:
            rel = 1.0
            dcg += rel / np.log2(i + 2)  # i+2 because index starts at 0
    
    # Calculate IDCG (ideal DCG)
    idcg = 0.0
    num_relevant = min(len(relevant_ids), k)
    for i in range(num_relevant):
        idcg += 1.0 / np.log2(i + 2)
    
    if idcg == 0:
        return 0.0
    
    return dcg / idcg


def clean_text(text: str) -> str:
    """Clean text for display"""
    if pd.isna(text):
        return ""
    text = str(text)
    # Remove excessive whitespace
    text = re.sub(r'\s+', ' ', text)
    # Remove HTML tags if any
    text = re.sub(r'<[^>]+>', '', text)
    return text.strip()


def generate_search_criteria(
    user_query: Optional[str] = None,
    user_history: Optional[pd.DataFrame] = None,
    sustainability_mode: bool = False,
    llm_client: Optional[object] = None
) -> List[str]:
    """
    Generate precise search criteria from user query and history
    
    Args:
        user_query: Natural language query from user
        user_history: DataFrame with user's purchase history
        sustainability_mode: Whether to prioritize sustainable products
        llm_client: Optional LLM client for advanced criteria generation
    
    Returns:
        List of precise search criteria
    """
    # Get last 5 products from history
    last_5_products = []
    if user_history is not None and len(user_history) > 0:
        last_5_products = user_history.head(5)['title'].tolist()
    
    # Create prompt for criteria generation
    history_text = "\n".join([f"- {title}" for title in last_5_products]) if last_5_products else "Aucun historique disponible"
    
    criteria_prompt = f"""Tu es un expert en shopping personnalis√© ultra-pr√©cis.

√Ä partir de cette requ√™te utilisateur (ou historique d'achats), g√©n√®re 8 √† 12 crit√®res de recherche tr√®s pr√©cis et vari√©s que l'utilisateur recherche implicitement.

R√©ponds EXACTEMENT sous ce format JSON (rien d'autre, pas de ```json) :

{{
  "expanded_criteria": [
    "crit√®re 1",
    "crit√®re 2",
    ...
  ]
}}

Requ√™te utilisateur : "{user_query if user_query else 'Aucune requ√™te sp√©cifique'}"

Historique r√©cent (si disponible) : {history_text}
"""
    
    # Try to use LLM if available
    if llm_client and hasattr(llm_client, 'generate'):
        try:
            response = llm_client.generate(criteria_prompt, temperature=0.3, max_tokens=1000)
            # Parse JSON response
            json_match = re.search(r'\{.*?"expanded_criteria".*?\}', response, re.DOTALL)
            if json_match:
                criteria_data = json.loads(json_match.group(0))
                criteria = criteria_data.get('expanded_criteria', [])
                if criteria and len(criteria) >= 8:
                    return criteria[:12]
        except Exception as e:
            print(f"Error generating criteria with LLM: {e}, falling back to rule-based")
    
    # Fallback to rule-based criteria extraction
    criteria = []
    
    if user_query:
        query_lower = user_query.lower()
        
        # Extract price information
        if any(word in query_lower for word in ['sous', 'moins de', 'inf√©rieur', 'budget', 'prix']):
            criteria.append("prix raisonnable ou dans le budget")
        
        # Extract material information
        if 'v√©gan' in query_lower or 'vegan' in query_lower:
            criteria.append("cuir v√©gan ou mat√©riaux alternatifs")
        if 'recycl√©' in query_lower or 'recycled' in query_lower:
            criteria.append("mat√©riaux recycl√©s")
        if 'cuir' in query_lower:
            criteria.append("cuir authentique ou alternative v√©gan")
        
        # Extract sustainability
        if any(word in query_lower for word in ['durable', 'sustainable', '√©co', 'eco', 'bio', 'organic']):
            criteria.append("produit durable et √©co-responsable")
            criteria.append("marque certifi√©e B-Corp ou Fair Trade")
        
        # Extract color
        colors = ['noir', 'blanc', 'rouge', 'bleu', 'vert', 'marron', 'beige', 'gris']
        for color in colors:
            if color in query_lower:
                criteria.append(f"couleur {color} ou similaire")
                break
        
        # Extract size/weight
        if 'l√©ger' in query_lower or 'light' in query_lower:
            criteria.append("poids r√©duit")
        if 'compact' in query_lower:
            criteria.append("format compact")
        
        # Extract quality
        if any(word in query_lower for word in ['qualit√©', 'premium', 'haut de gamme']):
            criteria.append("note moyenne ‚â• 4.5 √©toiles")
            criteria.append("qualit√© premium")
        
        # Extract delivery
        if 'livraison' in query_lower:
            criteria.append("livraison gratuite ou rapide")
        
        # Extract origin
        if any(word in query_lower for word in ['france', 'europe', 'local', 'made in']):
            criteria.append("fabriqu√© en Europe ou localement")
        
        # Extract warranty
        if 'garantie' in query_lower:
            criteria.append("garantie minimum 2 ans")
        
        # Extract type/style
        if 'sac' in query_lower:
            criteria.append("sac bandouli√®re ou sac √† dos")
        if 'r√©sistant' in query_lower or 'waterproof' in query_lower:
            criteria.append("r√©sistant √† l'eau")
    
    # Add sustainability criteria if mode is enabled
    if sustainability_mode:
        criteria.extend([
            "produit durable et √©co-responsable",
            "marque certifi√©e B-Corp ou Fair Trade",
            "mat√©riaux recycl√©s ou biologiques",
            "emballage minimal ou recyclable"
        ])
    
    # Add criteria from history
    if last_5_products:
        # Analyze history to infer preferences
        criteria.append("style coh√©rent avec les achats pr√©c√©dents")
        criteria.append("qualit√© similaire aux produits pr√©c√©demment achet√©s")
    
    # Ensure we have at least 8 criteria
    default_criteria = [
        "note moyenne ‚â• 4.0 √©toiles",
        "avis clients positifs",
        "produit disponible en stock",
        "retour gratuit possible"
    ]
    
    # Combine and deduplicate
    all_criteria = list(set(criteria + default_criteria))
    
    # Return 8-12 criteria
    return all_criteria[:12] if len(all_criteria) >= 8 else (all_criteria + default_criteria)[:12]


def create_rag_prompt(
    user_history_summary: str,
    candidate_products: List[Dict],
    query: Optional[str] = None,
    sustainability_mode: bool = False,
    search_criteria: Optional[List[str]] = None
) -> str:
    """
    Create RAG prompt for LLM
    
    Args:
        user_history_summary: Summary of user's purchase history
        candidate_products: List of dicts with product info (top 100 from retrieval)
        query: Optional natural language query
        sustainability_mode: Whether to prioritize sustainable products
    
    Returns:
        Formatted prompt string
    """
    # Format candidate products
    products_text = ""
    for i, product in enumerate(candidate_products[:100], 1):  # Top 100
        products_text += f"\n{i}. ASIN: {product['asin']}\n"
        products_text += f"   Title: {product['title']}\n"
        products_text += f"   Category: {product.get('category', 'N/A')}\n"
        products_text += f"   Description: {product.get('description', '')[:200]}\n"
        products_text += f"   Retrieval Score: {product.get('score', 0):.4f}\n"
    
    sustainability_note = ""
    if sustainability_mode:
        sustainability_note = """
IMPORTANT: Prioritize products that are sustainable, eco-friendly, organic, recycled, or vegan.
Look for keywords like: organic, recycled, sustainable, eco-friendly, vegan, biodegradable, fair trade.
"""
    
    criteria_section = ""
    if search_criteria:
        criteria_list = "\n".join([f"- {criterion}" for criterion in search_criteria])
        criteria_section = f"""
Precise Search Criteria (implicit user requirements):
{criteria_list}

IMPORTANT: Prioritize products that match these criteria when ranking.
"""
    
    prompt = f"""You are an expert product recommendation assistant for an e-commerce platform.

User's Purchase History:
{user_history_summary}

{f"User Query: {query}" if query else ""}

{criteria_section}

Candidate Products (retrieved from similarity search):
{products_text}

Your task:
1. Analyze the user's purchase history and preferences
2. From the candidate products above, select the TOP 10 most relevant products
3. Re-rank them in order of relevance (1 = most relevant)
4. For each product, provide a natural, convincing explanation (2-3 sentences) explaining why you recommend it

{sustainability_note}

Output your recommendations in the following JSON format:
{{
  "recommendations": [
    {{
      "rank": 1,
      "asin": "B00XXXXX",
      "explanation": "Why this product is perfect for the user..."
    }},
    ...
  ]
}}

Be specific and reference the user's past purchases when relevant. Make the explanations engaging and personalized.
"""
    
    return prompt


def parse_llm_response(response_text: str) -> List[Dict]:
    """Parse LLM JSON response"""
    try:
        # Try to extract JSON from markdown code blocks
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
        if json_match:
            response_text = json_match.group(1)
        
        # Try to find JSON object
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if json_match:
            response_text = json_match.group(0)
        
        data = json.loads(response_text)
        return data.get('recommendations', [])
    except Exception as e:
        print(f"Error parsing LLM response: {e}")
        print(f"Response text: {response_text[:500]}")
        return []


def generate_synthetic_user_profiles(
    category: str = "Electronics",
    num_profiles: int = 10,
    llm_client: Optional[object] = None,
    products_df: Optional[pd.DataFrame] = None
) -> List[Dict[str, Any]]:
    """
    Generate synthetic user profiles for benchmarking
    
    Args:
        category: Product category (e.g., "Electronics", "Clothing", "Home")
        num_profiles: Number of profiles to generate (default: 10)
        llm_client: Optional LLM client for advanced profile generation
        products_df: Optional DataFrame with products to sample realistic purchases
    
    Returns:
        List of user profile dicts with user_id, persona, past_purchases, natural_queries
    """
    # Create prompt for LLM generation
    prompt = f"""Tu es un g√©n√©rateur de donn√©es synth√©tiques ultra-r√©alistes pour benchmark de recommandation.

Cr√©e {num_profiles} profils utilisateurs tr√®s diff√©rents qui ach√®tent sur Amazon dans la cat√©gorie {category}.

Pour chaque utilisateur, donne :
- Un petit persona (√¢ge, genre, situation, valeurs principales)
- Ses 5 √† 12 derniers achats (titres r√©els ou tr√®s plausibles du dataset)
- 3 requ√™tes en langage naturel qu'il pourrait taper (vari√©es : une vague, une pr√©cise, une avec contrainte budget/durabilit√©)

R√©ponds UNIQUEMENT en JSON valide, rien d'autre :

[
  {{
    "user_id": "synthetic_001",
    "persona": "Femme 29 ans, graphiste freelance √† Lisbonne, tr√®s sensible √† la durabilit√© et au design scandinave",
    "past_purchases": ["Lampe LED en bois recycl√©", "T-shirt en coton bio oversize", "Sac √† dos Fj√§llr√§ven K√•nken recycl√©"],
    "natural_queries": [
      "lampe de bureau design et √©colo",
      "v√™tements en mati√®res recycl√©es pas trop chers",
      "sac √† dos r√©sistant √† l'eau vegan sous 120‚Ç¨"
    ]
  }},
  ...
]
"""
    
    # Try to use LLM if available
    if llm_client and hasattr(llm_client, 'generate'):
        try:
            response = llm_client.generate(prompt, temperature=0.7, max_tokens=4000)
            # Parse JSON response
            json_match = re.search(r'\[.*?\]', response, re.DOTALL)
            if json_match:
                profiles = json.loads(json_match.group(0))
                if profiles and len(profiles) >= num_profiles:
                    return profiles[:num_profiles]
        except Exception as e:
            print(f"Error generating profiles with LLM: {e}, falling back to template-based")
    
    # Fallback to template-based generation
    profiles = []
    
    # Template personas for different user types
    personas_templates = [
        {
            "persona": "Femme 29 ans, graphiste freelance √† Lisbonne, tr√®s sensible √† la durabilit√© et au design scandinave",
            "purchases": ["Lampe LED en bois recycl√©", "T-shirt en coton bio oversize", "Sac √† dos Fj√§llr√§ven K√•nken recycl√©", "Coussin en lin naturel", "Stylo rechargeable en m√©tal"],
            "queries": ["lampe de bureau design et √©colo", "v√™tements en mati√®res recycl√©es pas trop chers", "sac √† dos r√©sistant √† l'eau vegan sous 120‚Ç¨"]
        },
        {
            "persona": "Homme 42 ans, ing√©nieur √† Paris, passionn√© de technologie et qualit√© premium",
            "purchases": ["Casque audio sans fil premium", "Montre connect√©e sport", "Chargeur rapide USB-C", "√âcouteurs Bluetooth pro", "Powerbank haute capacit√©"],
            "queries": ["casque audio professionnel", "montre connect√©e avec GPS et r√©sistance √† l'eau", "chargeur rapide pour iPhone et Android"]
        },
        {
            "persona": "Femme 35 ans, m√®re de 2 enfants √† Lyon, recherche praticit√© et durabilit√©",
            "purchases": ["Aspirateur robot autonome", "Machine √† laver √©conome", "Coussin ergonomique", "Organisateur de rangement", "Brosse √† dents √©lectrique"],
            "queries": ["aspirateur robot pas cher", "produits m√©nagers √©cologiques", "objets durables pour la maison"]
        },
        {
            "persona": "Homme 28 ans, √©tudiant en design √† Berlin, budget serr√© mais go√ªt pour le design",
            "purchases": ["√âcouteurs filaires bon march√©", "Clavier m√©canique budget", "Souris ergonomique", "Lampadaire design", "C√¢ble USB-C"],
            "queries": ["√©couteurs pas chers avec bonne qualit√© son", "clavier m√©canique sous 50‚Ç¨", "accessoires tech design et abordables"]
        },
        {
            "persona": "Femme 50 ans, professeure √† Marseille, pr√©f√®re la qualit√© et le made in France",
            "purchases": ["Livre √©lectronique", "Carnet en cuir fran√ßais", "Stylo plume de qualit√©", "Lampe de lecture", "Marque-pages magn√©tiques"],
            "queries": ["produits fran√ßais de qualit√©", "livre √©lectronique avec r√©tro-√©clairage", "accessoires de bureau durables"]
        },
        {
            "persona": "Homme 33 ans, entrepreneur √† Barcelone, aime les produits innovants et √©cologiques",
            "purchases": ["Smartphone reconditionn√©", "Chargeur solaire portable", "Enceinte Bluetooth √©tanche", "Montre fitness", "√âcouteurs sans fil"],
            "queries": ["smartphone reconditionn√© fiable", "produits tech √©cologiques", "accessoires nomades durables"]
        },
        {
            "persona": "Femme 26 ans, influenceuse lifestyle √† Amsterdam, recherche esth√©tique et tendance",
            "purchases": ["Enceinte Bluetooth design", "Coque de t√©l√©phone personnalis√©e", "Lampadaire LED color√©", "Organisateur de bureau", "Miroir avec LED"],
            "queries": ["produits design pour Instagram", "d√©co tendance pas ch√®re", "accessoires tech esth√©tiques"]
        },
        {
            "persona": "Homme 45 ans, consultant √† Londres, privil√©gie efficacit√© et professionnalisme",
            "purchases": ["Ordinateur portable professionnel", "Souris ergonomique", "Casque avec r√©duction de bruit", "Chargeur universel", "Hub USB-C"],
            "queries": ["√©quipement de bureau professionnel", "casque avec ANC de qualit√©", "accessoires pour t√©l√©travail"]
        },
        {
            "persona": "Femme 31 ans, m√©decin √† Zurich, recherche hygi√®ne et praticit√©",
            "purchases": ["St√©rilisateur UV", "Balance connect√©e", "Tensiom√®tre digital", "Lampe de bureau m√©dicale", "Organisateur de m√©dicaments"],
            "queries": ["produits d'hygi√®ne innovants", "appareils m√©dicaux fiables", "objets pratiques pour la sant√©"]
        },
        {
            "persona": "Homme 38 ans, musicien √† Vienne, passionn√© de son et qualit√© audio",
            "purchases": ["Casque audio studio", "Interface audio USB", "Microphone professionnel", "Enceinte monitoring", "C√¢bles audio de qualit√©"],
            "queries": ["√©quipement audio professionnel", "casque studio avec bonne r√©ponse fr√©quentielle", "microphone USB pour enregistrement"]
        }
    ]
    
    # Generate profiles from templates
    for i in range(min(num_profiles, len(personas_templates))):
        template = personas_templates[i]
        profiles.append({
            "user_id": f"synthetic_{i+1:03d}",
            "persona": template["persona"],
            "past_purchases": template["purchases"][:np.random.randint(5, 13)],
            "natural_queries": template["queries"]
        })
    
    # If we need more profiles, generate variations
    while len(profiles) < num_profiles:
        base_template = np.random.choice(personas_templates)
        profiles.append({
            "user_id": f"synthetic_{len(profiles)+1:03d}",
            "persona": base_template["persona"].replace("29 ans", f"{np.random.randint(20, 55)} ans"),
            "past_purchases": np.random.choice(base_template["purchases"], size=np.random.randint(5, 10), replace=False).tolist(),
            "natural_queries": base_template["queries"]
        })
    
    return profiles[:num_profiles]

